[package]
name = "llamaclick"
version = "0.1.0"
edition = "2021"
description = "A colorful, intelligent CLI application for web automation powered by LLMs"
authors = ["LlamaSearch AI <info@llamasearch.ai>"]
license = "MIT"
repository = "https://github.com/llamasearch/llamaclick"
homepage = "https://llamasearch.ai/llamaclick"
documentation = "https://docs.rs/llamaclick"
readme = "README.md"
keywords = ["cli", "automation", "web", "llm", "ai"]
categories = ["command-line-utilities", "web-programming"]

[dependencies]
# Command-line interface
clap = { version = "4.4", features = ["derive", "cargo"] }
colored = "2.0"
indicatif = "0.17"
console = "0.15"
dialoguer = "0.11"
figlet-rs = "0.1"
terminal_size = "0.2"

# Async runtime
tokio = { version = "1.32", features = ["full"] }
futures = "0.3"

# Error handling
thiserror = "1.0"
anyhow = "1.0"

# Serialization
serde = { version = "1.0", features = ["derive"] }
serde_json = "1.0"
toml = "0.8"

# Web automation
playwright = "0.0.20"
headless_chrome = { version = "1.0", optional = true }
fantoccini = { version = "0.19", optional = true }

# HTTP client
reqwest = { version = "0.11", features = ["json"] }

# Utilities
directories = "5.0"
rand = "0.8"
lazy_static = "1.4"
chrono = "0.4"
log = "0.4"
env_logger = "0.10"
regex = "1.9"
url = "2.4"
uuid = { version = "1.4", features = ["v4"] }

# Cryptography for secure storage
ring = "0.17"
base64 = "0.21"

# Optional feature for local LLM integration
ollama-rs = { version = "0.1", optional = true }

[dev-dependencies]
tempfile = "3.8"
mockito = "1.2"
rstest = "0.18"
pretty_assertions = "1.4"
test-case = "3.1"

[features]
default = ["ollama", "chrome", "firefox"]
ollama = ["ollama-rs"]
chrome = ["headless_chrome"]
firefox = ["fantoccini"]
full = ["ollama", "chrome", "firefox"]

[profile.release]
lto = true
codegen-units = 1
panic = "abort"
strip = true

[package.metadata.docs.rs]
all-features = true
rustdoc-args = ["--cfg", "docsrs"]

[[bin]]
name = "llamaclick"
path = "src/main.rs" // Version bump
